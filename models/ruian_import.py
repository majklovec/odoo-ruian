# -*- coding: utf-8 -*-
import logging
import requests
import zipfile
import csv
from io import BytesIO, TextIOWrapper
from datetime import datetime, timedelta

from odoo import models, fields, api, _
from odoo.exceptions import UserError

_logger = logging.getLogger(__name__)


class RuianImport(models.Model):
    _name = "ruian.import"
    _description = "RUIAN Data Import"
    _progress_step = 1000  # Log progress every X records

    def _safe_float(self, value):
        try:
            return float(str(value).replace(",", ".").strip()) if value else 0.0
        except (TypeError, ValueError):
            return 0.0

    def _get_number_name(self, record):
        orient_number = record.get("ƒå√≠slo orientaƒçn√≠", "").strip()
        orient_letter = record.get("ƒå√≠slo orientaƒçn√≠ p√≠smeno", "").strip()
        if orient_number or orient_letter:
            return " ".join(filter(None, [orient_number, orient_letter]))
        domovni = record.get("ƒå√≠slo domovn√≠", "").strip()
        return domovni if domovni else _("Unknown")

    def _get_town_name(self, record):
        town = record.get("N√°zev obce", "").strip()
        part = record.get("N√°zev ƒç√°sti obce", "").strip()

        if part and part != town:
            return f"{town} - {part}"
        else:
            return town

    def run_ruian_import(self):
        """Main import method with full error handling and progress tracking"""
        _logger.info("=== Starting RUIAN import process ===")

        today = fields.Date.today()
        target_date = (today.replace(day=1) - timedelta(days=1)).strftime("%Y%m%d")

        start_time = datetime.now()

        try:
            zip_file = self._download_zip(target_date)
            file_count = sum(
                1 for f in zip_file.infolist() if f.filename.endswith(".csv")
            )
            _logger.info("üì¶ Archive contains %d CSV files", file_count)

            log = self.env["ruian.log"].create(
                {
                    "name": target_date,
                    "state": "running",
                    "start_date": fields.Datetime.now(),
                    "file_count": file_count,
                }
            )

            processed_files = 0
            global_stats = {
                "towns": 0,
                "streets": 0,
                "numbers": 0,
                "rows": 0,
                "warnings": 0,
            }

            towns = {}
            streets = {}
            numbers = {}

            for zip_info in zip_file.infolist():
                if not zip_info.filename.endswith(".csv"):
                    continue

                processed_files += 1
                file_start = datetime.now()
                _logger.info(
                    "üìÅ Processing file %d/%d: %s",
                    processed_files,
                    file_count,
                    zip_info.filename,
                )

                try:
                    with zip_file.open(zip_info) as csv_file:
                        reader = csv.DictReader(
                            TextIOWrapper(csv_file, encoding="windows-1250"),
                            delimiter=";",
                        )
                        file_stats = self._process_csv_file(
                            reader, towns, streets, numbers, global_stats
                        )

                    duration = (datetime.now() - file_start).total_seconds()
                    _logger.info(
                        "‚úÖ Processed %d rows in %.2fs (T+:%d S+:%d N+:%d W:%d)",
                        file_stats["rows"],
                        duration,
                        file_stats["new_towns"],
                        file_stats["new_streets"],
                        file_stats["new_numbers"],
                        file_stats["warnings"],
                    )

                    _logger.info(
                        "‚úÖ Global %d files, %d rows in %.2fs (T+:%d S+:%d N+:%d W:%d)",
                        processed_files,
                        global_stats["rows"],
                        duration,
                        global_stats["new_towns"],
                        global_stats["new_streets"],
                        global_stats["new_numbers"],
                        global_stats["warnings"],
                    )

                    log.write(
                        {
                            "rows": global_stats["rows"],
                            "towns": global_stats["towns"],
                            "streets": global_stats["streets"],
                            "numbers": global_stats["numbers"],
                            "warnings": global_stats["warnings"],
                            "files": processed_files,
                        }
                    )
                    self.env.cr.commit()

                except Exception as e:
                    self.env.cr.rollback()
                    _logger.error(
                        "üö® Rolling back changes for %s: %s", zip_info.filename, str(e)
                    )
                    global_stats["warnings"] += 1

            total_duration = (datetime.now() - start_time).total_seconds()
            _logger.info("=" * 60)
            _logger.info("üèÅ Import completed in %.2f seconds", total_duration)
            _logger.info(
                "üìä Totals - Towns: %d, Streets: %d, Numbers: %d",
                global_stats["towns"],
                global_stats["streets"],
                global_stats["numbers"],
            )
            _logger.info("‚ö†Ô∏è  Warnings: %d", global_stats["warnings"])
            _logger.info("=" * 60)

            log.write(
                {
                    "state": "done",
                    "end_date": fields.Datetime.now(),
                    "rows": global_stats["rows"],
                    "towns": global_stats["towns"],
                    "streets": global_stats["streets"],
                    "numbers": global_stats["numbers"],
                    "warnings": global_stats["warnings"],
                }
            )
            self.env.cr.commit()
            _logger.info("üíæ Final commit completed")

        except Exception as e:
            self.env.cr.rollback()
            _logger.error("üö® Critical import failure: %s", str(e), exc_info=True)
            raise UserError(_("Import failed: %s") % str(e)) from e

    def _process_csv_file(self, reader, towns, streets, numbers, global_stats):
        """Process individual CSV file with batch optimizations"""
        file_stats = {
            "rows": 0,
            "new_towns": 0,
            "new_streets": 0,
            "new_numbers": 0,
            "warnings": 0,
        }

        for record in reader:
            file_stats["rows"] += 1
            global_stats["rows"] += 1

            if file_stats["rows"] % self._progress_step == 0:
                _logger.debug("‚è≥ Processed %d rows...", file_stats["rows"])

            try:
                town = self._process_town(record, towns, file_stats, global_stats)

                street = self._process_street(
                    record, streets, town, file_stats, global_stats
                )

                self._process_number(
                    record, numbers, town, street, file_stats, global_stats
                )

                if file_stats["rows"] % 10000 == 0:
                    self.env.cr.commit()
                    _logger.debug(
                        "üíæ Intermediate commit at row %d", file_stats["rows"]
                    )

            except Exception as e:
                _logger.warning("‚ö†Ô∏è Row %d error: %s", file_stats["rows"], str(e))
                file_stats["warnings"] += 1
                global_stats["warnings"] += 1

        return file_stats

    def _download_zip(self, target_date):
        """Secure file download without chunking"""
        url = f"https://vdp.cuzk.gov.cz/vymenny_format/csv/{target_date}_OB_ADR_csv.zip"
        _logger.info("‚¨áÔ∏è Downloading from: %s", url)

        try:
            start = datetime.now()
            response = requests.get(url, timeout=30)
            response.raise_for_status()

            zip_buffer = BytesIO(response.content)

            _logger.info(
                "üì• Downloaded %.2f MB in %.2fs",
                len(zip_buffer.getvalue()) / (1024 * 1024),
                (datetime.now() - start).total_seconds(),
            )

            zip_file = zipfile.ZipFile(zip_buffer)
            if corrupt := zip_file.testzip():
                raise zipfile.BadZipFile(f"Corrupt file: {corrupt}")

            _logger.info("üì¶ Validated ZIP with %d files", len(zip_file.infolist()))
            return zip_file

        except requests.RequestException as e:
            _logger.error("üö® Download failed: %s", str(e))
            raise UserError(_("Download failed: %s") % str(e)) from e
        except zipfile.BadZipFile as e:
            _logger.error("üö® Corrupted ZIP: %s", str(e))
            raise UserError(_("Invalid ZIP archive")) from e

    def _process_town(self, record, towns, file_stats, global_stats):
        """Handle town creation and validation"""
        town_code_str = record.get("K√≥d ƒç√°sti obce")
        if not town_code_str:
            return None

        try:
            town_code = int(town_code_str)
            if town_code in towns:
                return towns[town_code]

            town_data = {
                "code": town_code,
                "name": self._get_town_name(record),
                "postal_code": record.get("PSƒå", "").strip(),
            }

            existing_town = self.env["ruian.town"].search(
                [("code", "=", town_code)], limit=1
            )
            if existing_town:
                existing_town.write(town_data)
                town = existing_town
            else:
                town = self.env["ruian.town"].create(town_data)
                file_stats["new_towns"] += 1
                global_stats["towns"] += 1

            towns[town_code] = town
            _logger.debug("‚úÖ Upserted town: %s (%d)", town_data["name"], town_code)
            return town

        except Exception as e:
            _logger.warning("‚ö†Ô∏è Town error in row %d: %s", file_stats["rows"], str(e))
            file_stats["warnings"] += 1
            return None

    def _process_street(self, record, streets, town, file_stats, global_stats):
        """Handle street creation and town linking"""
        street_name = record.get("N√°zev ulice", "").strip()
        if not street_name:
            return None

        existing_street = self.env["ruian.street"].search(
            [("name", "=", street_name)], limit=1
        )
        if existing_street:
            street = existing_street
        else:
            street = self.env["ruian.street"].create({"name": street_name})
            file_stats["new_streets"] += 1
            global_stats["streets"] += 1

        streets[street_name] = street
        if town and town.id not in street.town_ids.ids:
            street.write({"town_ids": [(4, town.id)]})

        _logger.debug("‚úÖ Upserted street: %s", street_name)
        return street

    def _process_number(self, record, numbers, town, street, file_stats, global_stats):
        """Handle number creation and relationships"""
        number_code_str = record.get("K√≥d ADM")
        if not number_code_str:
            return

        try:
            number_code = int(number_code_str)

            number_data = {
                "code": number_code,
                "name": self._get_number_name(record),
                "coord_x": self._safe_float(record.get("Sou≈ôadnice X")),
                "coord_y": self._safe_float(record.get("Sou≈ôadnice Y")),
                "town_id": town.id if town else False,
                "street_id": street.id if street else False,
            }

            existing_number = self.env["ruian.number"].search(
                [("code", "=", number_code)], limit=1
            )
            if existing_number:
                existing_number.write(number_data)
                number = existing_number
            else:
                number = self.env["ruian.number"].create(number_data)
                file_stats["new_numbers"] += 1
                global_stats["numbers"] += 1

            numbers[number_code] = number

            if street and number.id not in street.number_ids.ids:
                street.write({"number_ids": [(4, number.id)]})

            _logger.debug(
                "‚úÖ Upserted number: %s (%d)", number_data["name"], number_code
            )

        except Exception as e:
            _logger.warning("‚ö†Ô∏è Number error in row %d: %s", file_stats["rows"], str(e))
            file_stats["warnings"] += 1
